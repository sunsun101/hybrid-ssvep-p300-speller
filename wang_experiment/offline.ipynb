{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\wang_experiment\\record\\sunsun_20230331_online\\sunsun_20230331_online.fif...\n",
      "    Range : 0 ... 119868 =      0.000 ...   479.472 secs\n",
      "Ready.\n",
      "Reading 0 ... 119868  =      0.000 ...   479.472 secs...\n",
      "Setting up band-stop filter\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower transition bandwidth: 1.50 Hz\n",
      "- Upper transition bandwidth: 1.50 Hz\n",
      "- Filter length: 551 samples (2.204 sec)\n",
      "\n",
      "Creating RawArray with float64 data, n_channels=9, n_times=114869\n",
      "    Range : 0 ... 114868 =      0.000 ...   459.472 secs\n",
      "Ready.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bci\\AppData\\Local\\Temp\\ipykernel_7524\\1610906362.py:5: RuntimeWarning: This filename (C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\wang_experiment\\record\\sunsun_20230331_online\\sunsun_20230331_online.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
      "  raw =  mne.io.read_raw_fif(fname,  preload = True)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>11 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>8 EEG, 1 Stimulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>250.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>125.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>00:07:40 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawArray | 9 x 114869 (459.5 s), ~7.9 MB, data loaded>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "\n",
    "\n",
    "fname = r\"C:\\Users\\bci\\Documents\\projects\\hybrid-ssvep-p300-speller\\wang_experiment\\record\\sunsun_20230331_online\\sunsun_20230331_online.fif\"\n",
    "raw =  mne.io.read_raw_fif(fname,  preload = True)\n",
    "raw.notch_filter([50,100], trans_bandwidth = 3)\n",
    "# raw.filter(5, 90, l_trans_bandwidth=2,h_trans_bandwidth=5,\n",
    "#         phase='zero-double')\n",
    "new_data = raw.get_data()[:,10*250:-10*250]\n",
    "raw_new = mne.io.RawArray(new_data, raw.info)\n",
    "montage = mne.channels.make_standard_montage('standard_1020')\n",
    "raw_new.set_montage(montage)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 events found\n",
      "Event IDs: [1 2 3 4 5 6 7 8 9]\n",
      "Not setting metadata\n",
      "45 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 45 events and 125 original time points ...\n",
      "0 bad epochs dropped\n",
      "(45, 9, 125)\n"
     ]
    }
   ],
   "source": [
    "events = mne.find_events(raw_new)\n",
    "epochs = mne.Epochs(raw=raw_new,events=events, baseline=None, tmin=0.14, tmax=0.64 - 1/250, reject=None, reject_by_annotation=False)\n",
    "data = epochs.get_data() \n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import scipy.io\n",
    "\n",
    "# data = data.reshape(9,5,9,1500)\n",
    "# print(data.shape)\n",
    "# print(data[:,:,8,:])\n",
    "# data = np.transpose(data, (1, 0, 2, 3))\n",
    "# data = np.transpose(data, (2, 3, 0, 1))\n",
    "\n",
    "# data_dict = {\n",
    "#     'data': data,\n",
    "#     'sfreq': 250,\n",
    "#     'ch_names': ['Fz', 'C3', 'Cz', 'C4', 'Pz', 'PO7', 'Oz', 'PO8', 'STIM MARKERS'],\n",
    "#     'n_samples': data.shape[1]\n",
    "# }\n",
    "# scipy.io.savemat('sunsun.mat', data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 45 events and 125 original time points ...\n"
     ]
    }
   ],
   "source": [
    "X = epochs.get_data()[:, :-1, :] * 1e-6  # micro-volt default\n",
    "y = epochs.events[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45, 8, 125)\n",
      "(45,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ndarray\n",
    "import numpy as np\n",
    "from scipy.sparse import vstack, identity, spmatrix\n",
    "from typing import Optional, cast, Union\n",
    "from scipy.linalg import eigh\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from joblib import Parallel, delayed\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "def _ged_wong(\n",
    "    Z: ndarray,\n",
    "    D: Optional[ndarray] = None,\n",
    "    P: Optional[ndarray] = None,\n",
    "    n_components=1,\n",
    "    method=\"type1\",\n",
    "):\n",
    "    if method != \"type1\" and method != \"type2\":\n",
    "        raise ValueError(\"not supported method type\")\n",
    "\n",
    "    A = Z\n",
    "    if D is not None:\n",
    "        A = D.T @ A\n",
    "    if P is not None:\n",
    "        A = P.T @ A\n",
    "    A = A.T @ A\n",
    "    if method == \"type1\":\n",
    "        B = Z\n",
    "        if D is not None:\n",
    "            B = D.T @ Z\n",
    "        B = B.T @ B\n",
    "        if isinstance(A, spmatrix) or isinstance(B, spmatrix):\n",
    "            D, W = eigsh(A, k=n_components, M=B)\n",
    "        else:\n",
    "            D, W = eigh(A, B)\n",
    "    elif method == \"type2\":\n",
    "        if isinstance(A, spmatrix):\n",
    "            D, W = eigsh(A, k=n_components)\n",
    "        else:\n",
    "            D, W = eigh(A)\n",
    "\n",
    "    D_exist = cast(ndarray, D)\n",
    "    ind = np.argsort(D_exist)[::-1]\n",
    "    D_exist, W = D_exist[ind], W[:, ind]\n",
    "    return D_exist[:n_components], W[:, :n_components]\n",
    "\n",
    "\n",
    "def _trca_kernel(X: ndarray):\n",
    "    \"\"\"TRCA.\n",
    "    X: (n_trials, n_channels, n_samples)\n",
    "    \"\"\"\n",
    "    X = np.reshape(X, (-1, *X.shape[-2:]))\n",
    "    M, C, N = X.shape\n",
    "    n_components = C\n",
    "    P = vstack([identity(N) for _ in range(M)])\n",
    "    P = P @ P.T\n",
    "    Z = np.hstack(X).T  # type: ignore\n",
    "    _, U = _ged_wong(Z, None, P, n_components=n_components)  # U for X\n",
    "    return U\n",
    "\n",
    "\n",
    "def _trca_feature(\n",
    "    X: ndarray,\n",
    "    templates: ndarray,\n",
    "    Us: ndarray,\n",
    "    n_components: int = 1,\n",
    "    ensemble: bool = True,\n",
    "):\n",
    "    rhos = []\n",
    "    if not ensemble:\n",
    "        for Xk, U in zip(templates, Us):\n",
    "            a = U[:, :n_components].T @ X\n",
    "            b = U[:, :n_components].T @ Xk\n",
    "            a = np.reshape(a, (-1))\n",
    "            b = np.reshape(b, (-1))\n",
    "            rhos.append(pearsonr(a, b)[0])\n",
    "    else:\n",
    "        U = Us[:, :, :n_components]\n",
    "        U = np.concatenate(U, axis=-1)\n",
    "        for Xk in templates:\n",
    "            a = U.T @ X\n",
    "            b = U.T @ Xk\n",
    "            a = np.reshape(a, (-1))\n",
    "            b = np.reshape(b, (-1))\n",
    "            rhos.append(pearsonr(a, b)[0])\n",
    "    return rhos\n",
    "\n",
    "\n",
    "class TRCA(BaseEstimator, TransformerMixin, ClassifierMixin):\n",
    "    def __init__(\n",
    "        self, n_components: int = 1, ensemble: bool = True, n_jobs: Optional[int] = None\n",
    "    ):\n",
    "        self.n_components = n_components\n",
    "        self.ensemble = ensemble\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "    def fit(self, X: ndarray, y: ndarray, Yf: Optional[ndarray] = None):\n",
    "        self.classes_ = np.unique(y)\n",
    "        X = np.reshape(X, (-1, *X.shape[-2:]))\n",
    "        X = X - np.mean(X, axis=-1, keepdims=True)\n",
    "        self.templates_ = np.stack(\n",
    "            [np.mean(X[y == label], axis=0) for label in self.classes_]\n",
    "        )\n",
    "\n",
    "        self.Us_ = np.stack([_trca_kernel(X[y == label]) for label in self.classes_])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X: ndarray):\n",
    "        X = np.reshape(X, (-1, *X.shape[-2:]))\n",
    "        X = X - np.mean(X, axis=-1, keepdims=True)\n",
    "        n_components = self.n_components\n",
    "        templates = self.templates_\n",
    "        Us = self.Us_\n",
    "        ensemble = self.ensemble\n",
    "        rhos = Parallel(n_jobs=self.n_jobs)(\n",
    "            delayed(\n",
    "                partial(\n",
    "                    _trca_feature, Us=Us, n_components=n_components, ensemble=ensemble\n",
    "                )\n",
    "            )(a, templates)\n",
    "            for a in X\n",
    "        )\n",
    "        rhos = np.stack(rhos)\n",
    "        return rhos\n",
    "\n",
    "    def predict(self, X: ndarray):\n",
    "        feat = self.transform(X)\n",
    "        labels = self.classes_[np.argmax(feat, axis=-1)]\n",
    "        return labels\n",
    "\n",
    "\n",
    "def generate_cca_references(\n",
    "    freqs,\n",
    "    srate,\n",
    "    T,\n",
    "    phases: Optional[Union[ndarray, int, float]] = None,\n",
    "    n_harmonics: int = 1,\n",
    "):\n",
    "    if isinstance(freqs, int) or isinstance(freqs, float):\n",
    "        freqs = [freqs]\n",
    "    freqs = np.array(freqs)[:, np.newaxis]\n",
    "    if phases is None:\n",
    "        phases = 0\n",
    "    if isinstance(phases, int) or isinstance(phases, float):\n",
    "        phases = np.array([phases])\n",
    "    phases = np.array(phases)[:, np.newaxis]\n",
    "    t = np.linspace(0, T, int(T * srate))\n",
    "\n",
    "    Yf = []\n",
    "    for i in range(n_harmonics):\n",
    "        Yf.append(\n",
    "            np.stack(\n",
    "                [\n",
    "                    np.sin(2 * np.pi * (i + 1) * freqs * t + np.pi * phases),\n",
    "                    np.cos(2 * np.pi * (i + 1) * freqs * t + np.pi * phases),\n",
    "                ],\n",
    "                axis=1,\n",
    "            )\n",
    "        )\n",
    "    Yf = np.concatenate(Yf, axis=1)\n",
    "    return Yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 3 2 2 9 5 9 2 4 2 2 1 5 1]\n",
      "[5 8 2 9 9 5 3 7 3 7 2 6 7 1]\n",
      "0.42857142857142855\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "estimator=TRCA(n_components = 1, n_jobs=-1)\n",
    "model = estimator.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "acc = np.mean(preds == y_test)\n",
    "print(preds)\n",
    "print(y_test)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "Fold 0:\n",
      "  Train:  [2 2 2 2 7 7 7 7 5 5 5 5 4 4 4 4 1 1 1 1 6 6 6 6 3 3 3 3 9 9 9 9 8 8 8 8]\n",
      "  Test:  [2 7 5 4 1 6 3 9 8]\n",
      "[2 2 5 1 7 1 3 7 3]\n",
      "[2 7 5 4 1 6 3 9 8]\n",
      "0.3333333333333333\n",
      "Fold 1:\n",
      "  Train:  [2 2 2 2 7 7 7 7 5 5 5 5 4 4 4 4 1 1 1 1 6 6 6 6 3 3 3 3 9 9 9 9 8 8 8 8]\n",
      "  Test:  [2 7 5 4 1 6 3 9 8]\n",
      "[2 2 5 3 6 1 3 8 9]\n",
      "[2 7 5 4 1 6 3 9 8]\n",
      "0.3333333333333333\n",
      "Fold 2:\n",
      "  Train:  [2 2 2 2 7 7 7 7 5 5 5 5 4 4 4 4 1 1 1 1 6 6 6 6 3 3 3 3 9 9 9 9 8 8 8 8]\n",
      "  Test:  [2 7 5 4 1 6 3 9 8]\n",
      "[2 2 2 4 6 1 1 4 8]\n",
      "[2 7 5 4 1 6 3 9 8]\n",
      "0.3333333333333333\n",
      "Fold 3:\n",
      "  Train:  [2 2 2 2 7 7 7 7 5 5 5 5 4 4 4 4 1 1 1 1 6 6 6 6 3 3 3 3 9 9 9 9 8 8 8 8]\n",
      "  Test:  [2 7 5 4 1 6 3 9 8]\n",
      "[2 5 5 1 1 6 3 3 1]\n",
      "[2 7 5 4 1 6 3 9 8]\n",
      "0.5555555555555556\n",
      "Fold 4:\n",
      "  Train:  [2 2 2 2 7 7 7 7 5 5 5 5 4 4 4 4 1 1 1 1 6 6 6 6 3 3 3 3 9 9 9 9 8 8 8 8]\n",
      "  Test:  [2 7 5 4 1 6 3 9 8]\n",
      "[7 7 5 4 6 5 1 3 1]\n",
      "[2 7 5 4 1 6 3 9 8]\n",
      "0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "estimator=TRCA(n_components = 1, n_jobs=-1)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)\n",
    "print(skf)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: \", y[train_index])\n",
    "    print(f\"  Test: \", y[test_index])\n",
    "    model = estimator.fit(X[train_index], y[train_index])\n",
    "    preds = model.predict(X[test_index])\n",
    "    acc = np.mean(preds == y[test_index])\n",
    "    print(preds)\n",
    "    print(y[test_index])\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hybrid-ssvep-p300-speller-ZL_XZSnA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00051bd54bd81d25d26bce35c1b532f210659eeff443feda6c334d3d89679700"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
